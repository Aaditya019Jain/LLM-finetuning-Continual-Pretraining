# LLM-finetuning-Continual-Pretraining

This repository containes the latext compatible scripts for Continual Pre-training, fintuning of LLMs using Deep Speed to run them on multiple GPUs and if needed multiple nodes.
